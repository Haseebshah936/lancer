  // Constraints - will be used by getUserMedia() for customizing the audio and video
  //TODO - Read More about MediaTrackConstraints and MediaTrackSettings
  //LINK  - https://developer.mozilla.org/en-US/docs/Web/API/MediaTrackConstraints
  //LINK - https://developer.mozilla.org/en-US/docs/Web/API/MediaTrackSettings


  /** ANCHOR - handleStartStream
   * *This function will be called when the user clicks on the "Start Call" button.
   * *It is used to get user camera and microphone feed as a MediaStream object.
   * *You can Customize the constraints object to customize the audio and video.
   * *The MediaStream object is then looped over and indivudal tracks are added to the       RTCPeerConnection object.
   * *These tracks are added to the RTCPeerConnection object using the addTrack() method.
   * *Individual Tracks can be assigned to individual streams. As second parameter to addTrack() you can pass the stream object. addTrack(track, stream0, stream1, stream2, ...)
   * *The track can also be sent without any stream. addTrack(track) as I did for screen share.
   */


   /** ANCHOR - sendSingle
   * *useCallback is used to prevent the function from being recreated on every render
   * *This function is used as a callback to send the offer to the other peer
   * *It is called when a new track is added and onTrack event is fired
   * *In this case it is called when user toggles the screen share or camera
   * NOTE -
   * *To have the same state and not an old state of the time when listner was added. As even listners can create a cache and cause bugs.
   */


   /** ANCHOR - messageChange
   * *This function is a callback fired when a new message is received on the data channel
   * *It is used to handle the offer and answer messages sent for negotiation
   * *It is also used to add the received message to the chat
   * *It is called through useCallBack to make sure the function has the same state and does not have an old state. Of the time when listner was added. As even listners can create a cache and cause bugs.
   */


   /** ANCHOR -  handleNegotiation
   * *This function is used to handle the negotiation needed event
   * *It is called when the negotiationneeded event is fired
   * *It is fired when a new track is added to the RTCPeerConnection object
   * *Read the note in addTrack() docs for more info. Then the one below.
   * LINK - https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/negotiationneeded_event
   * *It is used to create an offer and set it as the local description
   * *It is then sent to the other peer using the data channel
   */


/** ANCHOR - handleOnTrack
   * *This function is used to handle the onTrack event
   * *It is fired when a new track is added to the RTCPeerConnection object
   * *It recieves MediaStream Objects array in the event object
   * *The can have multiple streams and each stream can have multiple
   */
        /**  NOTE
        * *This 'if' is just used in the start of the connection in this use case as I am handling audio and video sepratly and not in the same stream. So later on when the video track is added to the RTCPeerConnection object the onTrack event is fired and the video track is added to the video element. But the audio track is already added to the audio element. So the if is used to prevent the audio track from being added to the video element.
        */

        /** REVIEW
       * * Creating a new stream and adding the track to it. This is done to keep the audio track in a seprate stream and the video track in a seprate stream. This is done for a various reasons.
       * *1. To be able to mute the audio track without muting the video track
       * *2. To not keep the audio track away the video track. So the audio can be still shared even if the video is not shared or the camera is off or the screen is shared.
       * *3 To be able to have full control over the audio and video tracks.
       * *4 As audio track can be muted and unmuted without the need to create a new stream. By setting the enabled property of the audio track to true or false. This is possible with the video track as well. But the camera resource is not released when the video track is disabled. So it is better to remove the stream when the video track is disabled. And add a new stream when the video track is enabled.
       */

       /** NOTE -
       * *Setting the remote stream to the video stream. This stream is later added to the video element in the useEffect hook below.
       */

        /**  NOTE -
       * *If the stream is not present in the event object. Then the track is added to a new stream and the stream is set as the remote stream. This is the MediaDevices.getUserMedia() stream.(Screen share or camera stream)
       */

/** ANCHOR - handleStartConnection
   * *This method will be called when the user clicks on the "Start Call" button
   * *It will crate a new RTCPeerConnection
   * *It will create a new RTCDataChannel
   * *It will call the handleStartStream() method to get the user's audio and video
   * *It will add event listeners to the RTCPeerConnection for track addition, negotiation, and data channel
   */